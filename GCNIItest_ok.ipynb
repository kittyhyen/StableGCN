{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 pretrained/021e5ff276774e0cbcff8553fb8d5be6.pt\n",
      " pair ===== 33333333 PN\n",
      "Epoch:0010 train loss:1.867 acc:47.86 | val loss:1.855 acc:72.20\n",
      "Epoch:0020 train loss:1.703 acc:64.29 | val loss:1.650 acc:75.80\n",
      "Epoch:0030 train loss:1.445 acc:60.71 | val loss:1.375 acc:78.00\n",
      "Epoch:0040 train loss:1.177 acc:74.29 | val loss:1.140 acc:78.60\n",
      "Epoch:0050 train loss:1.028 acc:76.43 | val loss:0.993 acc:77.80\n",
      "Epoch:0060 train loss:0.978 acc:70.71 | val loss:0.861 acc:79.20\n",
      "Epoch:0070 train loss:0.928 acc:76.43 | val loss:0.810 acc:79.40\n",
      "Epoch:0080 train loss:0.787 acc:78.57 | val loss:0.774 acc:79.40\n",
      "Epoch:0090 train loss:0.771 acc:82.14 | val loss:0.749 acc:78.60\n",
      "Epoch:0100 train loss:0.821 acc:79.29 | val loss:0.735 acc:79.40\n",
      "Epoch:0110 train loss:0.730 acc:82.86 | val loss:0.704 acc:79.80\n",
      "Epoch:0120 train loss:0.646 acc:82.14 | val loss:0.712 acc:79.00\n",
      "Epoch:0130 train loss:0.658 acc:77.86 | val loss:0.705 acc:79.60\n",
      "Epoch:0140 train loss:0.672 acc:83.57 | val loss:0.682 acc:79.40\n",
      "Epoch:0150 train loss:0.728 acc:77.14 | val loss:0.696 acc:79.40\n",
      "Epoch:0160 train loss:0.725 acc:82.14 | val loss:0.696 acc:79.20\n",
      "Epoch:0170 train loss:0.578 acc:88.57 | val loss:0.689 acc:79.40\n",
      "Epoch:0180 train loss:0.600 acc:85.71 | val loss:0.662 acc:80.40\n",
      "Epoch:0190 train loss:0.614 acc:85.00 | val loss:0.661 acc:80.60\n",
      "Epoch:0200 train loss:0.540 acc:89.29 | val loss:0.654 acc:80.80\n",
      "Train cost: 16.4078s\n",
      "Load 199th epoch\n",
      "Test acc.:83.50\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from utils import *\n",
    "from model import *\n",
    "import uuid\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Training settings\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"seed\": 50,\n",
    "    \"epochs\": 200,\n",
    "    \"lr\": 0.01,\n",
    "    \"wd1\": 0.01,\n",
    "    \"wd2\": 5e-4,\n",
    "    \"layer\": 32,\n",
    "    \"hidden\": 64,\n",
    "    \"dropout\": 0.6,\n",
    "    \"patience\": 100,\n",
    "    \"data\": 'cora',\n",
    "    \"dev\": 0,\n",
    "    \"alpha\": 0.1,\n",
    "    \"lamda\": 0.5,\n",
    "    \"variant\": False,\n",
    "    \"test\": True\n",
    "})\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Load data\n",
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation(args.data)\n",
    "cudaid = \"cuda:\"+str(args.dev)\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "checkpt_file = 'pretrained/'+uuid.uuid4().hex+'.pt'\n",
    "print(cudaid,checkpt_file)\n",
    "\n",
    "model = GCNII(nfeat=features.shape[1],\n",
    "                nlayers=args.layer,\n",
    "                nhidden=args.hidden,\n",
    "                nclass=int(labels.max()) + 1,\n",
    "                dropout=args.dropout,\n",
    "                lamda = args.lamda, \n",
    "                alpha=args.alpha,\n",
    "                variant=args.variant,\n",
    "                 pair='PN').to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "                        {'params':model.params1,'weight_decay':args.wd1},\n",
    "                        {'params':model.params2,'weight_decay':args.wd2},\n",
    "                        ],lr=args.lr)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    \n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()   \n",
    "    \n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test():\n",
    "    model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "result = {}    \n",
    "t_total = time.time()\n",
    "bad_counter = 0\n",
    "best = 999999999\n",
    "best_epoch = 0\n",
    "acc = 0\n",
    "for epoch in range(args.epochs):\n",
    "    loss_tra,acc_tra = train()\n",
    "    loss_val,acc_val = validate()\n",
    "\n",
    "    if(epoch+1)%10 == 0: \n",
    "        print('Epoch:{:04d}'.format(epoch+1),\n",
    "            'train',\n",
    "            'loss:{:.3f}'.format(loss_tra),\n",
    "            'acc:{:.2f}'.format(acc_tra*100),\n",
    "            '| val',\n",
    "            'loss:{:.3f}'.format(loss_val),\n",
    "            'acc:{:.2f}'.format(acc_val*100))\n",
    "  \n",
    "    if loss_val < best:\n",
    "        best = loss_val\n",
    "        best_epoch = epoch\n",
    "        acc = acc_val\n",
    "        torch.save(model.state_dict(), checkpt_file)\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "    if bad_counter == args.patience:\n",
    "        break\n",
    "\n",
    "if args.test:\n",
    "    acc = test()[1]\n",
    "\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print('Load {}th epoch'.format(best_epoch))\n",
    "print(\"Test\" if args.test else \"Val\",\"acc.:{:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 pretrained/d03a65c31d53475eb9ed961cd2a001e1.pt\n",
      " pair ===== 33333333 \n"
     ]
    },
    {
     "ename": "ModuleAttributeError",
     "evalue": "'GCNII' object has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a8ac3c69210f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mloss_tra\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_tra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-a8ac3c69210f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GCNII/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py38/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    779\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'GCNII' object has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training settings\n",
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "    \"seed\": 38,\n",
    "    \"epochs\": 200,\n",
    "    \"lr\": 0.01,\n",
    "    \"wd1\": 0.01,\n",
    "    \"wd2\": 5e-4,\n",
    "    \"layer\": 64,\n",
    "    \"hidden\": 64,\n",
    "    \"dropout\": 0.6,\n",
    "    \"patience\": 100,\n",
    "    \"data\": 'citeseer',\n",
    "    \"dev\": 0,\n",
    "    \"alpha\": 0.1,\n",
    "    \"lamda\": 0.5,\n",
    "    \"variant\": False,\n",
    "    \"test\": True\n",
    "})\n",
    "\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Load data\n",
    "adj, features, labels,idx_train,idx_val,idx_test = load_citation(args.data)\n",
    "cudaid = \"cuda:\"+str(args.dev)\n",
    "device = torch.device(cudaid)\n",
    "features = features.to(device)\n",
    "adj = adj.to(device)\n",
    "checkpt_file = 'pretrained/'+uuid.uuid4().hex+'.pt'\n",
    "print(cudaid,checkpt_file)\n",
    "\n",
    "model = GCNII(nfeat=features.shape[1],\n",
    "                nlayers=args.layer,\n",
    "                nhidden=args.hidden,\n",
    "                nclass=int(labels.max()) + 1,\n",
    "                dropout=args.dropout,\n",
    "                lamda = args.lamda, \n",
    "                alpha=args.alpha,\n",
    "                variant=args.variant,\n",
    "                 pair='').to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "                        {'params':model.params1,'weight_decay':args.wd1},\n",
    "                        {'params':model.params2,'weight_decay':args.wd2},\n",
    "                        ],lr=args.lr)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features,adj)\n",
    "    \n",
    "    acc_train = accuracy(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train = F.nll_loss(output[idx_train], labels[idx_train].to(device))\n",
    "    loss_train.backward()\n",
    "    optimizer.step()   \n",
    "    \n",
    "    return loss_train.item(),acc_train.item()\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features,adj)\n",
    "        loss_val = F.nll_loss(output[idx_val], labels[idx_val].to(device))\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val].to(device))\n",
    "        return loss_val.item(),acc_val.item()\n",
    "\n",
    "def test():\n",
    "    model.load_state_dict(torch.load(checkpt_file))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(features, adj)\n",
    "        loss_test = F.nll_loss(output[idx_test], labels[idx_test].to(device))\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test].to(device))\n",
    "        return loss_test.item(),acc_test.item()\n",
    "result = {}    \n",
    "t_total = time.time()\n",
    "bad_counter = 0\n",
    "best = 999999999\n",
    "best_epoch = 0\n",
    "acc = 0\n",
    "for epoch in range(args.epochs):\n",
    "    loss_tra,acc_tra = train()\n",
    "    loss_val,acc_val = validate()\n",
    "\n",
    "    if(epoch+1)%20 == 0: \n",
    "        print('Epoch:{:04d}'.format(epoch+1),\n",
    "            'train',\n",
    "            'loss:{:.3f}'.format(loss_tra),\n",
    "            'acc:{:.6f}'.format(acc_tra*100),\n",
    "            '| val',\n",
    "            'loss:{:.3f}'.format(loss_val),\n",
    "            'acc:{:.6f}'.format(acc_val*100))\n",
    "  \n",
    "    if loss_val < best:\n",
    "        best = loss_val\n",
    "        best_epoch = epoch\n",
    "        acc = acc_val\n",
    "        torch.save(model.state_dict(), checkpt_file)\n",
    "        bad_counter = 0\n",
    "    else:\n",
    "        bad_counter += 1\n",
    "\n",
    "    if bad_counter == args.patience:\n",
    "        break\n",
    "\n",
    "if args.test:\n",
    "    acc = test()[1]\n",
    "\n",
    "print(\"Train cost: {:.4f}s\".format(time.time() - t_total))\n",
    "print('Load {}th epoch'.format(best_epoch))\n",
    "print(\"Test\" if args.test else \"Val\",\"acc.:{:.2f}\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
